# 计算机操作系统

## 操作系统基础

1.GUI和SHELL区别

​	图形化界面(Graphical User Interface, GUI)

​	指令界面

2.CPU

​	寄存器-保存关键变量与临时结果

​	特殊寄存器----程序计数器----指向下一条需要从内存提取指令的地址

​	堆栈指针---指向内存中当前栈顶端

​	程序状态寄存器----PSW---跟踪当前系统状态

​	

​	时间多路复用CPU

3.CPU模式-内核态和用户态

​	PSW中属性控制何种状态

​	内核态--执行任何指令集中指令 并且使用硬件功能

​	用户态--执行部分指令

​	用户调用---系统调用----进入内核态

4.多线程与多核芯片

​	多线程----实际上简单的多线程还是一个线程 并不是并发

5.内存

​	快速 量大 便宜

​	![image-20220802163821242](计算机操作系统.assets/image-20220802163821242.png)

​	寄存器---最顶层

​	CPU一样材料，和CPU一样快

​	高速缓存

​	划为高速缓存行

​	内存---RAM

​	磁盘-硬盘

6.I/O设备

7.总线

![image-20220803170539675](计算机操作系统.assets/image-20220803170539675.png)

8.计算机启动过程

​	主板上 有-BIOS 基本 输入 输出 系统

​	BIOS检查RAM数量，键盘和其他基础设备---查找PCle和CPL总线

​	CMOS启动设备

​	BIOS配置程序进入外部或者硬盘内部启动操作系统

9.文件-树机构

​	Linux上有特殊文件

​	线程--文件之间交互----管道

## 硬件结构

### 	1.CPU怎么执行程序的？

​	   实际上就是按照栈读取的方式执行程序-----读入---判断---执行

###### 		1.1 冯诺依曼模型

​       **运算器、控制器、存储器、输入设备、输出设备**，这 5 个部分也被称为**冯诺依曼模型**

​		运算器、控制器是在中央处理器里的，存储器就我们常见的内存，输入输出设备则是计算机外接的设备，比如键盘就是输入设备，显示器就是输出设备。

​		存储单元和输入输出设备要与中央处理器打交道的话，离不开总线。

###### 		1.2 程序执行过程

​		 CPU 执行程序的过程如下：

​		读取程序计数器----指令内存地址---CPU通过内存地址找到内存

​		读取指令寄存器---确定类型+参数----分为逻辑运算或者控制单元执行

​		程序计数器自增---指向下一条指令

### 2.内存 硬盘运行速度为什么不同？

###### 		1.存储器的层次结构

​		寄存器

​		CPU Cache-----L1 L2 L3

​		内存

​		硬盘

###### 		2.存储器类比关系

​	![image-20220808144725751](计算机操作系统.assets/image-20220808144725751.png)

​		复习看书

​		大脑--CPU

​		 大脑正在思考---寄存器

​		 大脑 的短期记忆——L1

​		 大脑长期记忆--L2 L3

​		内存

​		硬盘

###### 		3.CPU高速缓存 Cache

​		CPU 的高速缓存，通常可以分为 L1、L2、L3 这样的三层高速缓存，也称为一级缓存、二级缓存、三级缓存。

​		L1 高速缓存通常分成**指令缓存**和**数据缓存**。

​		L2 高速缓存同样每个 CPU 核心都有

​		L3 高速缓存通常是多个 CPU 核心共用的

###### 		4.内存

​		内存用的芯片和 CPU Cache 有所不同，它使用的是一种叫作 **DRAM （\*Dynamic Random Access Memory\*，动态随机存取存储器）** 的芯片。

​		只有不断刷新，数据才能被存储起来。

###### 		5.硬盘

​		速度慢

###### 		6.CPU怎么读取Cache中的数据？

​		直接映射为例子

​		根据内存地址中索引信息，计算在 CPU Cahe 中的索引，也就是找出对应的 CPU Cache Line 的地址

​		找到对应 CPU Cache Line 后，判断 CPU Cache Line 中的有效位，确认 CPU Cache Line 中数据是否是有效的，如果是无效的，CPU 就会直接访问内存，并重新加载数据，如果数据有效，则往下执行

​		对比内存地址中组标记和 CPU Cache Line 中的组标记，确认 CPU Cache Line 中的数据是我们要访问的内存数据，如果不是的话，CPU 就会直接访问内存，并重新加载数据，如果是的话，则往下执行

​		根据内存地址中偏移量信息，从 CPU Cache Line 的数据块中，读取对应的字

​		加速方式：

​		1.**遇到这种遍历数组的情况时，按照内存布局顺序访问，将可以有效的利用 CPU Cache 带来的好处，这样我们代码的性能就会得到很大的提升**

​		2.绑定CPU某个核心，不再度加载L1 L2缓存

### 3.CPU缓存一致性

###### 		1.那在什么时机才把 Cache 中的数据写回到内存呢

- 写直达（*Write Through*）

- 写回（*Write Back*）

  保持内存与 Cache 一致性最简单的方式是，**把数据同时写入内存和 Cache 中**，这种方法称为**写直达（\*Write Through\*）**。

  **当发生写操作时，新的数据仅仅被写入 Cache Block 里，只有当修改过的 Cache Block「被替换」时才需要写到内存中**

###### 		2.缓存一致性问题

​		由于 L1/L2 Cache 是多个核心各自独有的，那么会带来多核心的**缓存一致性（\*Cache Coherence\*）** 的问题

​		和数据库中的幻读一个意思实际上。



​		怎么解决？

​		某个 CPU 核心里的 Cache 数据更新时，必须要传播到其他核心的 Cache，这个称为**写传播（\*Write Propagation\*）**----数据一致

​		某个 CPU 核心里对数据的操作顺序，必须在其他核心看起来顺序是一样的，这个称为**事务的串行化（\*Transaction Serialization\*）**-----数据可以复现

​		

###### 		3.实现数据的传播-----总线嗅探

​		老方法---总线嗅探

​		变量i变化---发广播---所有cpu自检--有一致

###### 		4.MESI协议

​		MESI 协议其实是 4 个状态单词的开头字母缩写，分别是：

- *Modified*，已修改
- *Exclusive*，独占
- *Shared*，共享
- *Invalidated*，已失效

### 4.CPU如何执行任务？

###### 		1.CPU伪分享问题

​		这种因为多个线程同时读写同一个 Cache Line 的不同变量时，而导致 CPU Cache 失效的现象称为**伪共享（\*False Sharing\*）**

###### 		2.解决方式

​		对于多个线程共享的热点数据，即经常会修改的数据，应该避免这些数据刚好在同一个 Cache Line 中，否则就会出现为伪共享的问题

​		空间换时间

###### 		3.CPU怎么选择线程的？

​		CFS完全公平调度---为每个任务安排一个虚拟运行时间 vruntime



### 5.什么是软中断？

###### 	1.中断的上下部分

​	中断处理程序的上部分和下半部可以理解为：

- **上半部直接处理硬件请求，也就是硬中断**，主要是负责耗时短的工作，特点是快速执行；
- **下半部是由内核触发，也就说软中断**，主要是负责上半部未完成的工作，通常都是耗时比较长的事情，特点是延迟执行；

​	硬中断（上半部）是会打断 CPU 正在执行的任务，然后立即执行中断处理程序，而软中断（下半部）是以内核线程的方式执行

###### 	2.如何定位软中断 CPU 使用率过高的问题？

​	抓包解决

### 6.0.1+0.2==0.3？

###### 	1.为什么负数要用补码表示？

​	负数不是使用补码的方式表示，则在做基本对加减法运算的时候，**还需要多一步操作来判断是否为负数，如果为负数，还得把加法反转成减法，或者把减法反转成加法**

​	**用了补码的表示方式，对于负数的加减法操作，实际上是和正数加减法操作一样的**。

###### 	2.十进制小数与二进制的转换

​	**没办法用二进制精确的表示 0.1，只能用「近似值」来表示，就是在有限的精度情况下，最大化接近 0.1 的二进制数，于是就会造成精度缺失的情况**

###### 	3.计算机是怎么存小数的？

​	计算机存储小数的采用的是**浮点数**，名字里的「浮点」表示小数点是可以浮动的。

​	计算机是以浮点数的形式存储小数的，大多数计算机都是 IEEE 754 标准定义的浮点数格式，包含三个部分：

- 符号位：表示数字是正数还是负数，为 0 表示正数，为 1 表示负数；
- 指数位：指定了小数点在数据中的位置，指数可以是负数，也可以是正数，指数位的长度越长则数值的表达范围就越大；
- 尾数位：小数点右侧的数字，也就是小数部分，比如二进制 1.0011 x 2^(-2)，尾数部分就是 0011，而且尾数的长度决定了这个数的精度，因此如果要表示精度更高的小数，则就要提高尾数位的长度；

用 32 位来表示的浮点数，则称为单精度浮点数，也就是我们编程语言中的 float 变量，而用 64 位来表示的浮点数，称为双精度浮点数，也就是 double 变量。

###### 	4.0.1 + 0.2 == 0.3 吗？

​	不是的，0.1 和 0.2 这两个数字用二进制表达会是一个一直循环的二进制数



## 内存管理（重要）

### 1.为什么要有虚拟内存？

###### 	1.单片机

​	**单片机的 CPU 是直接操作内存的「物理地址」**

​	在这种情况下，要想在内存中同时运行两个程序是不可能的。如果第一个程序在 2000 的位置写入一个新的值，将会擦掉第二个程序存放在相同位置上的所有内容，所以同时运行两个程序是根本行不通的，这两个程序会立刻崩溃。

###### 	2.虚拟内存

​	操作系统是如何解决这个问题呢？---两个程序引用一个绝对地址

​	把进程所使用的地址「隔离」开来，即让操作系统为每个进程分配独立的一套「**虚拟地址**」

​	前提：每个进程都不能访问物理地址

​	**操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。**

​	虚拟---物理



​	进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址

​	![image-20220809231731457](C:\Users\ps\AppData\Roaming\Typora\typora-user-images\image-20220809231731457.png)

###### 	3.操作系统是如何管理虚拟地址与物理地址之间的关系？

​	主要有两种方式，分别是**内存分段和内存分页**

###### 	4.内存分段

​	程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。

​	**不同的段是有不同的属性的，所以就用分段（\*Segmentation\*）的形式把这些段分离出来。**

###### 	5.分段机制下，虚拟地址和物理地址是如何映射的？

​	分段机制下的虚拟地址由两部分组成，**段选择因子**和**段内偏移量**。



​	段选择因子----哪种类型？

​	段内偏移量----这个类型的第几个？

​	段选择因子和段内偏移量：

- **段选择子**就保存在段寄存器里面。段选择子里面最重要的是**段号**，用作段表的索引。**段表**里面保存的是这个**段的基地址、段的界限和特权等级**等。
- 虚拟地址中的**段内偏移量**应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。

![image-20220809232120418](C:\Users\ps\AppData\Roaming\Typora\typora-user-images\image-20220809232120418.png)

###### 6.分段机制会产生哪些问题？

分段的办法很好，解决了程序本身不需要关心具体的物理内存地址的问题，但它也有一些不足之处：

- 第一个就是**内存碎片**的问题。
- 第二个就是**内存交换的效率低**的问题。

###### 7.分段为什么会产生内存碎片的问题？

​	某个程序占用的内存不是连续的------间隔占用---再开只能选择填充这些被分开的

我们来看看这样一个例子。假设有 1G 的物理内存，用户执行了多个程序，其中：

- 游戏占用了 512MB 内存
- 浏览器占用了 128MB 内存
- 音乐占用了 256 MB 内存。

这个时候，如果我们关闭了浏览器，则空闲内存还有 1024 - 512 - 256 = 256MB。

如果这个 256MB 不是连续的，被分成了两段 128 MB 内存，这就会导致没有空间再打开一个 200MB 的程序。

![image-20220809232434567](计算机操作系统.assets/image-20220809232434567.png)

###### 8.解决「外部内存碎片」的问题就是**内存交换**？

​	可以把音乐程序占用的那 256MB 内存写到硬盘上，然后再从硬盘上读回来到内存里。不过再读回的时候，我们不能装载回原来的位置，而是紧紧跟着那已经被占用了的 512MB 内存后面。这样就能空缺出连续的 256MB 空间，于是新的 200MB 程序就可以装载进来。

这个内存交换空间，在 Linux 系统里，也就是我们常看到的 Swap 空间，这块空间是从硬盘划分出来的，用于内存与硬盘的空间交换。

​	用A---存A---放A----放在B的紧挨着

###### 9.分段为什么会导致内存交换效率低的问题？

​	每次都要将内存存到硬盘里 再读取一次

​	**如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。**

###### 10.为了解决内存分段的「外部内存碎片和内存交换效率低」的问题，就出现了内存分页

​	能少出现一些内存碎片的办法+进行内存交换的时候，让需要交换写入或者从磁盘装载的数据更少一点

​	**分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小**。这样一个连续并且尺寸固定的内存空间，我们叫**页**（*Page*）。在 Linux 下，每一页的大小为 `4KB`。

​	程序用的时候---不能自己划分想要多少是多少---只能选择多少份

​	虚拟地址与物理地址之间通过**页表**来映射

​	![image-20220809234453857](计算机操作系统.assets/image-20220809234453857.png)

​	页表是存储在内存里的，**内存管理单元** （*MMU*）就做将虚拟内存地址转换成物理地址的工作。

###### 11.分页是怎么解决分段的「外部内存碎片和内存交换效率低」的问题？

​	**采用了分页，页与页之间是紧密排列的，所以不会有外部碎片。**

​	因为内存分页机制分配内存的最小单位是一页，即使程序不足一页大小，我们最少只能分配一个页，所以页内会出现内存浪费，所以针对**内存分页机制会有内部内存碎片**的现象

​	操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为**换出**（*Swap Out*）。一旦需要的时候，再加载进来，称为**换入**（*Swap In*）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，**内存交换的效率就相对比较高。**

​	核心：可以采用那些穿插的内存地址

​	**只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。**

###### 12.分页机制下，虚拟地址和物理地址是如何映射的？

​	哪一页+页里的哪个地址

​	分页机制下，虚拟地址分为两部分，**页号**和**页内偏移**。

![image-20220809235239073](计算机操作系统.assets/image-20220809235239073.png)

###### 	13.多级分页

​	**如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表**。

​	**页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 100 多万个页表项来映射，而二级分页则只需要 1024 个页表项**

​	对于 64 位的系统，两级分页肯定不够了，就变成了四级目录，分别是：

- 全局页目录项 PGD（*Page Global Directory*）；
- 上层页目录项 PUD（*Page Upper Directory*）；
- 中间页目录项 PMD（*Page Middle Directory*）；
- 页表项 PTE（*Page Table Entry*）；

![image-20220809235516965](计算机操作系统.assets/image-20220809235516965.png)

###### 14.TLB----内存里的缓存

​	最常访问的几个页表项存储到访问速度更快的硬件，于是计算机科学家们，就在 CPU 芯片中，加入了一个专门存放程序最常访问的页表项的 Cache，这个 Cache 就是 TLB（*Translation Lookaside Buffer*） ，通常称为页表缓存、转址旁路缓存、快表等。

​	![image-20220809235629940](计算机操作系统.assets/image-20220809235629940.png)

​	在 CPU 芯片里面，封装了内存管理单元（*Memory Management Unit*）芯片，它用来完成地址转换和 TLB 的访问与交互。

有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。

TLB 的命中率其实是很高的，因为程序最常访问的页就那么几个。

###### 15.段页式内存管理

​	内存分段和内存分页并不是对立的，它们是可以组合起来在同一个系统中使用的，那么组合起来后，通常称为**段页式内存管理**。

​	每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号

![image-20220809235733205](计算机操作系统.assets/image-20220809235733205.png)

段页式地址变换中要得到物理地址须经过三次内存访问：

- 第一次访问段表，得到页表起始地址；
- 第二次访问页表，得到物理页号；
- 第三次将物理页号与页内位移组合，得到物理地址。

###### 16.Linux 内存管理

​	**页式内存管理的作用是在由段式内存管理所映射而成的地址上再加上一层地址映射。**

​	**Linux 内存主要采用的是页式内存管理，但同时也不可避免地涉及了段机制**。

​	在 Linux 操作系统中，虚拟地址空间的内部又被分为**内核空间和用户空间**两部分，不同位数的系统，地址空间的范围也不同。

![image-20220810000027747](计算机操作系统.assets/image-20220810000027747.png)

### 2.malloc 是如何分配内存的？

###### 1.Linux 进程的内存分布长什么样？

内核空间与用户空间的区别：

- 进程在用户态时，只能访问用户空间内存；
- 只有进入内核态后，才可以访问内核空间的内存；

每个进程都各自有独立的虚拟内存，但是**每个虚拟内存中的内核地址，其实关联的都是相同的物理内存**。这样，进程切换到内核态后，就可以很方便地访问内核空间内存。

###### 2.malloc 是如何分配内存的？

​	使用 C 标准库的 `malloc()或者 mmap()，` 可以分别在堆和文件映射段动态分配内存。

malloc 申请内存的时候，会有两种方式向操作系统申请堆内存。

- 方式一：通过 brk() 系统调用从堆分配内存
- 方式二：通过 mmap() 系统调用在文件映射区域分配内存；

方式一实现的方式很简单，就是通过 brk() 函数将「堆顶」指针向高地址移动，获得新的内存空间。

![image-20220810212855923](计算机操作系统.assets/image-20220810212855923.png)

方式二通过 mmap() 系统调用中「私有匿名映射」的方式，在文件映射区分配一块内存，也就是从文件映射区“偷”了一块内存。

![image-20220810212911662](计算机操作系统.assets/image-20220810212911662.png)

###### 3.什么场景下 malloc() 会通过 brk() 分配内存？又是什么场景下通过 mmap() 分配内存？

malloc() 源码里默认定义了一个阈值：

- 如果用户分配的内存小于 128 KB，则通过 brk() 申请内存；
- 如果用户分配的内存大于 128 KB，则通过 mmap() 申请内存；

###### 4.malloc() 分配的是物理内存吗？

**malloc() 分配的是虚拟内存**。

分配后的虚拟内存没有被访问的话，是不会将虚拟内存不会映射到物理内存，这样就不会占用物理内存了。

###### 5.malloc(x) 会分配多大的虚拟内存？

比预先要求的分配的稍微更大一点---X+N

**会预分配更大的空间作为内存池**。

###### 6.free 释放内存，会归还给操作系统吗？

堆调用内存---不会

- malloc 通过 **brk()** 方式申请的内存，free 释放内存的时候，**并不会把内存归还给操作系统，而是缓存在 malloc 的内存池中，待下次使用**；

匿名内存---会

- malloc 通过 **mmap()** 方式申请的内存，free 释放内存的时候，**会把内存归还给操作系统，内存得到真正的释放**。

###### 7.为什么不全部使用 mmap 来分配内存？

因为向操作系统申请内存，是要通过系统调用的，执行系统调用是要进入内核态的，然后在回到用户态，运行态的切换会耗费不少时间。

**频繁通过 mmap 分配的内存话，不仅每次都会发生运行态的切换，还会发生缺页中断（在第一次访问虚拟地址后），这样会导致 CPU 消耗较大**。

###### 8.为什么不全部使用 brk 来分配？

原因--当前缓存内的内存无法满足需求，一直保留，缓存越来越大

如果下次申请的内存大于 30k，没有可用的空闲内存空间，必须向 OS 申请，实际使用内存继续增大。

对于小块内存，堆内将产生越来越多不可用的碎片，导致“内存泄露”。

###### 9.free() 函数只传入一个内存地址，为什么能知道要释放多大的内存？

 malloc 返回给用户态的内存起始地址比进程的堆空间起始地址多了 16 字节吗？

这个多出来的 16 字节就是保存了该内存块的描述信息，比如有该内存块的大小。

### 3.内存满了，会发生什么？

###### 1.虚拟内存有什么作用？（复习）

虚拟内存可以使使用内存大于实际内存---CPU 访问内存会有很明显的重复访问的倾向性

每个进程的虚拟内存空间就是相互独立的---保证线程之间不会出现内存地址冲突

页表项中除了物理地址之外，还有一些标记属性的比特----在内存访问方面，操作系统提供了更好的安全性。

###### 2.内存分配的过程是怎样的？

虚拟内存没有映射到物理内存---**缺页中断**

**缺页中断**-----是否有空闲的物理内存，如果有，就直接分配物理内存，并建立虚拟内存与物理内存之间的映射关系

没有---**回收内存**

- **后台内存回收**（kswapd）：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程**异步**的，不会阻塞进程的执行。
- **直接内存回收**（direct reclaim）：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是**同步**的，会阻塞进程的执行。

直接内存回收后，空闲的物理内存仍然无法满足此次物理内存的申请，那么内核就会放最后的大招了 ——**触发 OOM （Out of Memory）机制**。

OOM Killer 机制会根据算法选择一个占用物理内存较高的进程，然后将其杀死，以便释放内存资源，如果物理内存依然不足，OOM Killer 会继续杀死占用物理内存较高的进程，直到释放足够的内存位置。

![image-20220810214304032](计算机操作系统.assets/image-20220810214304032.png)

![image-20220810214311120](计算机操作系统.assets/image-20220810214311120.png)

###### 3.哪些内存可以被回收？

主要有两类内存可以被回收，而且它们的回收方式也不同。

核心：可以被简单读取的---直接释放

​			不可以的----写入磁盘，下次再读取

- **文件页**（File-backed Page）：内核缓存的磁盘数据（Buffer）和内核缓存的文件数据（Cache）都叫作文件页。大部分文件页，都可以直接释放内存，以后有需要时，再从磁盘重新读取就可以了。而那些被应用程序修改过，并且暂时还没写入磁盘的数据（也就是脏页），就得先写入磁盘，然后才能进行内存释放。所以，**回收干净页的方式是直接释放内存，回收脏页的方式是先写回磁盘后再释放内存**。
- **匿名页**（Anonymous Page）：这部分内存没有实际载体，不像文件缓存有硬盘文件这样一个载体，比如堆、栈数据等。这部分内存很可能还要再次被访问，所以不能直接释放内存，它们**回收的方式是通过 Linux 的 Swap 机制**，Swap 会把不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。

###### 4.LRU算法（重要）----回收算法

​	文件页和匿名页的回收都是基于 LRU 算法，也就是优先回收不常访问的内存。

​	**LRU 回收算法，实际上维护着 active 和 inactive 两个双向链表（重要）**

- **active_list** 活跃内存页链表，这里存放的是最近被访问过（活跃）的内存页；
- **inactive_list** 不活跃内存页链表，这里存放的是很少被访问（非活跃）的内存页；

  核心：越接近链表尾部，就表示内存页越不常访问。这样，在回收内存时，系统就可以根据活跃程度，优先回收不活跃的内存。

​	活跃和非活跃的内存页，按照类型的不同，又分别分为文件页和匿名页。可以从 /proc/meminfo 中，查询它们的大小

![image-20220810214903966](计算机操作系统.assets/image-20220810214903966.png)

###### 5.回收内存带来的性能影响

​	直接内存回收，这种方式是同步回收的，会阻塞进程，这样就会造成很长时间的延迟，以及系统的 CPU 利用率会升高，最终引起系统负荷飙高。

​	对于干净页是直接释放内存，这个操作不会影响性能，而对于脏页会先写回到磁盘再释放内存，这个操作会发生磁盘 I/O 的，这个操作是会影响系统性能的。

​	如果开启了 Swap 机制，那么 Swap 机制会将不常访问的匿名页换出到磁盘中，下次访问时，再从磁盘换入到内存中，这个操作是会影响系统性能的。

​	回收内存的操作基本都会发生磁盘 I/O 的----所以导致才会卡

###### 6.调整文件页和匿名页的回收倾向----解决内存卡顿的方式

​	文件页---只有脏读情况下IO

​	匿名页的 Swap 换入换出这两个操作都会发生磁盘 I/O

​	匿名页的卡顿纪律大于文件页

​	Linux 提供了一个 `/proc/sys/vm/swappiness` 选项，用来调整文件页和匿名页的回收倾向。

​	范围是 0-100，数值越大，越积极使用 Swap

###### 7.尽早触发 kswapd 内核线程异步回收内存----解决内存卡顿的方式

​	如何查看系统的直接内存回收和后台内存回收的指标？

​	使用 `sar -B 1` 命令来观察

​	![image-20220810220115933](计算机操作系统.assets/image-20220810220115933.png)

- pgscank/s : kswapd(后台回收线程) 每秒扫描的 page 个数。
- pgscand/s: 应用程序在内存申请过程中每秒直接扫描的 page 个数。
- pgsteal/s: 扫描的 page 中每秒被回收的个数（pgscank+pgscand）。

###### 8.什么条件下才能触发 kswapd 内核线程回收内存呢？

​	**核心：当剩余内存页（pages_free）小于页低阈值（pages_low），就会触发 kswapd 进行后台回收，然后 kswapd 会一直回收到剩余内存页（pages_free）大于页高阈值（pages_high）**

​	

​	

![image-20220810220237912](计算机操作系统.assets/image-20220810220237912.png)

- 页最小阈值（pages_min）；
- 页低阈值（pages_low）；
- 页高阈值（pages_high）；

页低阈值（pages_low）可以通过内核选项 `/proc/sys/vm/min_free_kbytes` （该参数代表系统所保留空闲内存的最低限）来间接设置。

###### 9.什么是 SMP 架构？

​	**核心：CPU核心是完全公平的，没有优先核心**

​	SMP 指的是一种**多个 CPU 处理器共享资源的电脑硬件架构**

​	每个 CPU 地位平等，它们共享相同的物理资源，包括总线、内存、IO、操作系统等

​	每个 CPU 访问内存所用时间都是相同的，因此，这种系统也被称为一致存储访问结构（UMA，Uniform Memory Access）

​	CPU 处理器核数的增多，多个 CPU 都通过一个总线访问内存，这样总线的带宽压力会越来越大，同时每个 CPU 可用带宽会减少

###### 10.什么是NUMA 结构？

​	**核心：CPU不公平，有快速组**

​	 NUMA 结构，即非一致存储访问结构（Non-uniform memory access，NUMA）。

​	每个 CPU 进行了分组，每一组 CPU 用 Node 来表示，一个 Node 可能包含多个 CPU 。

​	**每个 Node 有自己独立的资源，包括内存、IO 等**，每个 Node 之间可以通过互联模块总线（QPI）进行通信，所以，也就意味着每个 Node 上的 CPU 都可以访问到整个系统中的所有内存。但是，访问远端 Node 的内存比访问本地内存要耗时很多。

###### 11.NUMA 架构跟回收内存有什么关系？

​	当前组不够，从其他组借

​	当某个 Node 内存不足时，系统可以从其他 Node 寻找空闲内存，也可以从本地内存中回收内存。

​	可以通过 /proc/sys/vm/zone_reclaim_mode 来控制：

- 0 （默认值）：在回收本地内存之前，在其他 Node 寻找空闲内存；
- 1：只回收本地内存；
- 2：只回收本地内存，在本地回收内存时，可以将文件页中的脏页写回硬盘，以回收内存。
- 4：只回收本地内存，在本地回收内存时，可以用 swap 方式回收内存。

###### 12.如何保护一个进程不被 OOM 杀掉呢？

​	Linux 内核里有一个 `oom_badness()` 函数，它会把系统中可以被杀掉的进程扫描一遍，并对每个进程打分，得分最高的进程就会被首先杀掉。

​	受下面这两个方面影响：

- 第一，进程已经使用的物理内存页面数。
- 第二，每个进程的 OOM 校准值 oom_score_adj。它是可以通过 `/proc/[pid]/oom_score_adj` 来配置的。我们可以在设置 -1000 到 1000 之间的任意一个数值，调整进程被 OOM Kill 的几率。

​	最终得分跟进程自身消耗的内存有关，消耗的内存越大越容易被杀掉。

​	如果你想某个进程无论如何都不能被杀掉，那你可以将 oom_score_adj 配置为 -1000。

###### 13.总结

内核在给应用程序分配物理内存的时候，如果空闲物理内存不够，那么就会进行内存回收的工作，主要有两种方式：

- 后台内存回收：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程异步的，不会阻塞进程的执行。
- 直接内存回收：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是同步的，会阻塞进程的执行。

可被回收的内存类型有文件页和匿名页：

- 文件页的回收：对于干净页是直接释放内存，这个操作不会影响性能，而对于脏页会先写回到磁盘再释放内存，这个操作会发生磁盘 I/O 的，这个操作是会影响系统性能的。
- 匿名页的回收：如果开启了 Swap 机制，那么 Swap 机制会将不常访问的匿名页换出到磁盘中，下次访问时，再从磁盘换入到内存中，这个操作是会影响系统性能的。

文件页和匿名页的回收都是基于 LRU 算法，也就是优先回收不常访问的内存。回收内存的操作基本都会发生磁盘 I/O 的，如果回收内存的操作很频繁，意味着磁盘 I/O 次数会很多，这个过程势必会影响系统的性能。

针对回收内存导致的性能影响，常见的解决方式。

- 设置 /proc/sys/vm/swappiness，调整文件页和匿名页的回收倾向，尽量倾向于回收文件页；
- 设置 /proc/sys/vm/min_free_kbytes，调整 kswapd 内核线程异步回收内存的时机；
- 设置 /proc/sys/vm/zone_reclaim_mode，调整 NUMA 架构下内存回收策略，建议设置为 0，这样在回收本地内存之前，会在其他 Node 寻找空闲内存，从而避免在系统还有很多空闲内存的情况下，因本地 Node 的本地内存不足，发生频繁直接内存回收导致性能下降的问题；

在经历完直接内存回收后，空闲的物理内存大小依然不够，那么就会触发 OOM 机制，OOM killer 就会根据每个进程的内存占用情况和 oom_score_adj 的值进行打分，得分最高的进程就会被首先杀掉。

我们可以通过调整进程的 /proc/[pid]/oom_score_adj 值，来降低被 OOM killer 杀掉的概率。

### 4.在 4GB 物理内存的机器上，申请 8G 内存会怎么样？

###### 1.操作系统虚拟内存大小

​	32 位操作系统和 64 位操作系统的虚拟地址空间大小是不同的，在 Linux 操作系统中，虚拟地址空间的内部又被分为**内核空间和用户空间**两部分

​	![image-20220810221503765](计算机操作系统.assets/image-20220810221503765.png)

###### 2.在 32 位操作系统、4GB 物理内存的机器上，申请 8GB 内存，会怎么样？

​	因为 32 位操作系统，进程最多只能申请 3 GB 大小的虚拟内存空间，所以进程申请 8GB 内存的话，在申请虚拟内存阶段就会失败。

###### 3.在 64 位操作系统、4GB 物理内存的机器上，申请 8G 内存，会怎么样？

​	64 位操作系统，进程可以使用 128 TB 大小的虚拟内存空间，所以进程申请 8GB 内存是没问题的，因为进程申请内存是申请虚拟内存，只要不读写这个虚拟内存，操作系统就不会分配物理内存。

###### 4.Swap 机制的作用

​	如果申请物理内存大小超过了空闲物理内存大小，就要看操作系统有没有开启 Swap 机制：

- 如果没有开启 Swap 机制，程序就会直接 OOM；
- 如果有开启 Swap 机制，程序可以正常运行。

###### 5.什么是 Swap 机制？

​	**硬盘和内存交换**

​	Swap 就是把一块磁盘空间或者本地文件，当成内存来使用，它包含换出和换入两个过程：

- **换出（Swap Out）** ，是把进程暂时不用的内存数据存储到磁盘中，并释放这些数据占用的内存；
- **换入（Swap In）**，是在进程再次访问这些内存的时候，把它们从磁盘读到内存中来；

​	频繁地读写硬盘，会显著降低操作系统的运行速率，这也是 Swap 的弊端。

###### 6.Swap 机制什么时候触发？

​	**内存不足和内存闲置的场景下触发**

- **内存不足**：当系统需要的内存超过了可用的物理内存时，内核会将内存中不常使用的内存页交换到磁盘上为当前进程让出内存，保证正在执行的进程的可用性，这个内存回收的过程是强制的直接内存回收（Direct Page Reclaim）。直接内存回收是同步的过程，会阻塞当前申请内存的进程。
- **内存闲置**：应用程序在启动阶段使用的大量内存在启动后往往都不会使用，通过后台运行的守护进程（kSwapd），我们可以将这部分只使用一次的内存交换到磁盘上为其他内存的申请预留空间。kSwapd 是 Linux 负责页面置换（Page replacement）的守护进程，它也是负责交换闲置内存的主要进程，它会在[空闲内存低于一定水位 (opens new window)](https://xiaolincoding.com/os/3_memory/mem_reclaim.html#尽早触发-kSwapd-内核线程异步回收内存)时，回收内存页中的空闲内存保证系统中的其他进程可以尽快获得申请的内存。kSwapd 是后台进程，所以回收内存的过程是异步的，不会阻塞当前申请内存的进程。

###### 7.Swap 换入换出的是什么类型的内存？

​	内核缓存的文件数据，因为都有对应的磁盘文件，所以在回收文件数据的时候， 直接写回到对应的文件就可以了。

​	Swap 分区---存放：匿名页：像进程的堆、栈数据等，它们是没有实际载体

###### 8.OOM--内存溢出

​	内存溢出(Out Of Memory，简称OOM)是指应用系统中存在无法回收的内存或使用的内存过多，最终使得程序运行要用到的内存大于能提供的最大内存。此时程序就运行不了，系统会提示内存溢出。



​	
